{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len of df_train:      230693\n",
      "Len of df_validation:  25633\n",
      "Len of df_test:        28481\n",
      "Len of df_original:   284807\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def readTrainDataframe():\n",
    "    return pd.read_csv(\"../Bases/treino.csv\")\n",
    "\n",
    "def readValidationDataframe():\n",
    "    return pd.read_csv(\"../Bases/validacao.csv\")\n",
    "\n",
    "def readTestDataframe():\n",
    "    return pd.read_csv(\"../Bases/teste.csv\")\n",
    "\n",
    "df_train = readTrainDataframe()\n",
    "df_validation = readValidationDataframe()\n",
    "df_test = readTestDataframe()\n",
    "df_original = pd.read_csv(\"../Bases/creditcard.csv\")\n",
    "\n",
    "print(f\"Len of df_train:      {len(df_train):6}\")\n",
    "print(f\"Len of df_validation: {len(df_validation):6}\")\n",
    "print(f\"Len of df_test:       {len(df_test):6}\")\n",
    "print(f\"Len of df_original:   {len(df_original):6}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python code from Blender build scripts\n",
    "# Changes from original code: 'bcolors' to 'colors'\n",
    "\n",
    "class colors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKCYAN = '\\033[96m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount', 'Class']\n"
     ]
    }
   ],
   "source": [
    "colsDef = df_test.columns\n",
    "colsForCompare = []\n",
    "\n",
    "for i in range(len(colsDef)):\n",
    "    if (colsDef[i] != 'Index'):\n",
    "        colsForCompare.append(colsDef[i])\n",
    "\n",
    "print(colsForCompare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mNo leaked information between train and validation\n",
      "\u001b[92mNo leaked information between train and test\n",
      "\u001b[92mNo leaked information between validation and test\n",
      "\u001b[94mThe following test is an proof to know if the function really works when there is a leak, it MUST fail\n",
      "\u001b[91m20 line(s) had leaked between train and validation\n"
     ]
    }
   ],
   "source": [
    "def howMuchInformationLeaked(df_A, df_B):\n",
    "    merged_df_left = pd.merge(df_A, df_B, on=colsForCompare)\n",
    "    how_much_leak_left = len(merged_df_left)\n",
    "\n",
    "    merged_df_right = pd.merge(df_B, df_A, on=colsForCompare)\n",
    "    how_much_leak_right = len(merged_df_right)\n",
    "\n",
    "    how_much_leak = max(how_much_leak_left, how_much_leak_right)\n",
    "\n",
    "    return how_much_leak\n",
    "\n",
    "#* Test between Train and Validation\n",
    "how_much_leak = howMuchInformationLeaked(df_train, df_validation)\n",
    "if (how_much_leak == 0):\n",
    "    print(f\"{colors.OKGREEN}No leaked information between train and validation\")\n",
    "else: \n",
    "    print(f\"{colors.FAIL}{how_much_leak} line(s) had leaked between train and validation\")\n",
    "\n",
    "#* Test between Train and Test\n",
    "how_much_leak = howMuchInformationLeaked(df_train, df_test)\n",
    "if (how_much_leak == 0):\n",
    "    print(f\"{colors.OKGREEN}No leaked information between train and test\")\n",
    "else: \n",
    "    print(f\"{colors.FAIL}{how_much_leak} line(s) had leaked between train and test\")\n",
    "\n",
    "#* Test between Validation and Test\n",
    "how_much_leak = howMuchInformationLeaked(df_validation, df_test)\n",
    "if (how_much_leak == 0):\n",
    "    print(f\"{colors.OKGREEN}No leaked information between validation and test\")\n",
    "else: \n",
    "    print(f\"{colors.FAIL}{how_much_leak} line(s) had leaked between validation and test\")\n",
    "\n",
    "#* Test to assure the realibity of 'howMuchInformationLeaked' function, this test MUST fail\n",
    "print(f\"{colors.OKBLUE}The following test is an proof to know if the function really works when there is a leak, it MUST fail\")\n",
    "df_validation.loc[1:20] = df_train.loc[1:20]\n",
    "\n",
    "how_much_leak = howMuchInformationLeaked(df_validation, df_train)\n",
    "if (how_much_leak == 0):\n",
    "    print(f\"{colors.OKGREEN}No leaked information between train and validation\")\n",
    "else: \n",
    "    print(f\"{colors.FAIL}{how_much_leak} line(s) had leaked between train and validation\")\n",
    "df_validation = readValidationDataframe()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
